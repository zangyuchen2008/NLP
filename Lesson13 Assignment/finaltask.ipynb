{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.random.seed(42)\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Dense, Embedding, SpatialDropout1D, concatenate\n",
    "from tensorflow.keras.layers import GRU, Bidirectional, GlobalAveragePooling1D, GlobalMaxPooling1D\n",
    "from tensorflow.keras.preprocessing import text, sequence\n",
    "from tensorflow.keras.callbacks import Callback\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import os\n",
    "os.environ['OMP_NUM_THREADS'] = '4'\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# downloaded fasttext w2v file\n",
    "EMBEDDING_FILE = os.path.join('wordvector','crawl-300d-2M.vec')\n",
    "\n",
    "train = pd.read_csv(os.path.join('jigsaw-toxic-comment-classification-challenge','train.csv'),encoding='utf8')\n",
    "test = pd.read_csv(os.path.join('jigsaw-toxic-comment-classification-challenge','test.csv'),encoding='utf8')\n",
    "submission = pd.read_csv(os.path.join('jigsaw-toxic-comment-classification-challenge','sample_submission.csv'),encoding='utf8')\n",
    "\n",
    "X_train = train[\"comment_text\"].fillna(\"fillna\").values\n",
    "y_train = train[[\"toxic\", \"severe_toxic\", \"obscene\", \"threat\", \"insult\", \"identity_hate\"]].values\n",
    "X_test = test[\"comment_text\"].fillna(\"fillna\").values\n",
    "\n",
    "\n",
    "max_features = 30000\n",
    "maxlen = 100\n",
    "embed_size = 300"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# create encoded sequence and word embedding index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = text.Tokenizer(num_words=max_features)#create a tokenizer class with max token limit\n",
    "tokenizer.fit_on_texts(list(X_train) + list(X_test))# creat and update vocabulary list\n",
    "X_train = tokenizer.texts_to_sequences(X_train)# create index(comming from vocabulary) based integer list to represent sequence\n",
    "X_test = tokenizer.texts_to_sequences(X_test)\n",
    "x_train = sequence.pad_sequences(X_train, maxlen=maxlen) # padding zeros to make 100 length encoded seq list, the default padding is pre padding\n",
    "x_test = sequence.pad_sequences(X_test, maxlen=maxlen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create embedding_index from fast text file\n",
    "def get_coefs(word, *arr): return word, np.asarray(arr, dtype='float32')\n",
    "embeddings_index = dict(get_coefs(*o.rstrip().rsplit(' ')) for o in open(EMBEDDING_FILE))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## storing and loading embedding index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings_index= pickle.load(open('embedding_index.dat','rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.0963, -0.4002,  0.1611, -0.4041,  0.2315,  0.202 ,  0.0109,\n",
       "       -0.1781, -0.1908, -0.1324,  0.4132,  0.1422,  0.2847,  0.0166,\n",
       "       -0.1647,  0.1435, -0.0917,  0.0537,  0.4343, -0.081 , -0.3396,\n",
       "        0.1352, -0.4702,  0.0374, -0.3001,  0.2118,  0.5446,  0.1056,\n",
       "        0.1796,  0.1589, -0.4196, -0.1554, -0.4651,  0.1017, -0.0182,\n",
       "        0.2802,  0.14  , -0.2426, -0.2327,  0.1124, -0.374 ,  0.1927,\n",
       "        0.1121, -0.009 , -0.0009,  0.1431, -0.021 ,  0.4263,  0.0913,\n",
       "       -0.2215, -0.4352,  0.1586,  0.1729,  0.0088, -0.2693, -0.174 ,\n",
       "       -0.0967,  0.0622, -0.4991, -0.0239, -0.1385,  0.1755,  0.0472,\n",
       "        0.1328,  0.1317,  0.1584,  0.3414, -0.1608, -0.2105, -0.2295,\n",
       "       -0.1174, -0.3036, -0.1816, -0.09  ,  0.3642,  0.1882, -0.1771,\n",
       "        0.2296,  0.1375, -0.2877,  0.1672, -0.2132,  0.0552, -0.0641,\n",
       "       -0.0297, -0.0938, -0.0734, -0.0783, -0.0185,  0.1572,  0.1998,\n",
       "        0.1876,  0.1425, -0.2362, -0.1263, -0.3583,  0.1297,  0.0814,\n",
       "       -0.5309, -0.1556,  0.1624, -0.1794, -0.3583, -0.3233,  0.4269,\n",
       "       -0.092 , -0.1752,  0.1038, -0.116 , -0.1801, -0.2219, -0.2027,\n",
       "        0.3733, -0.19  , -0.4119,  0.1236,  0.0452, -0.3157, -0.2208,\n",
       "       -0.6062,  0.0661, -0.0107, -0.3215, -0.0594,  0.074 , -0.1921,\n",
       "       -0.01  , -0.13  ,  0.5282,  0.0464,  0.1075, -0.0934,  0.2001,\n",
       "        0.0066,  0.2943, -0.155 ,  0.5752,  0.1664,  0.0213, -0.3905,\n",
       "       -0.1522, -0.024 , -0.1561, -0.2645, -0.2789, -0.0549,  0.1105,\n",
       "       -0.2452,  0.1537,  0.2586,  0.0611, -0.0926, -0.0268, -0.3178,\n",
       "       -0.058 ,  0.3836, -0.064 ,  0.2189, -0.0967, -0.1648,  0.4158,\n",
       "       -0.0826,  0.0066,  0.4146,  0.3206, -0.222 ,  0.1933,  0.2432,\n",
       "        0.4891, -0.1506,  0.0872,  0.2733, -0.3864,  0.0805, -0.6233,\n",
       "        0.4834, -0.1272,  0.123 ,  0.1917,  0.1259, -0.1495, -0.3073,\n",
       "        0.0198,  0.2639, -0.1586,  0.2207, -0.138 , -0.0257, -0.064 ,\n",
       "        0.1131, -0.1213,  0.0741, -0.2788,  0.3403,  0.0576, -0.0532,\n",
       "        0.4725,  0.3808,  0.1848,  0.1184, -0.1155, -0.0685,  0.4971,\n",
       "       -0.4694, -0.1128, -0.2766, -0.0641, -0.0754,  0.1481, -0.083 ,\n",
       "        0.024 ,  0.6067, -0.0708,  0.1387, -0.185 , -0.1146,  0.0228,\n",
       "       -0.288 ,  0.0296,  0.1307, -0.0927,  0.4279, -0.0897,  0.1639,\n",
       "        0.1867,  0.3452, -0.0734,  0.1481, -0.1708, -0.0192, -0.0177,\n",
       "        0.168 , -0.1889,  0.0792,  0.4634, -0.5559,  0.074 ,  0.0396,\n",
       "        0.0353, -0.2018,  0.0646,  0.0947,  0.146 , -0.0355,  0.0498,\n",
       "        0.4134, -0.1039,  0.03  , -0.1716, -0.0672,  0.0445,  0.1085,\n",
       "        0.0993,  0.4405, -0.1886, -0.1103,  0.4607,  0.1384,  0.0556,\n",
       "        0.0341, -0.058 ,  0.0888, -0.2184, -0.1655,  0.0957, -0.2067,\n",
       "        0.0661,  0.0252, -0.5242, -0.2691, -0.2287, -0.0282,  0.1351,\n",
       "        0.1596, -0.0194,  0.2085,  0.0782, -0.1786, -0.5671,  0.2539,\n",
       "       -0.0148, -0.26  ,  0.0556,  0.0477, -0.3434, -0.192 ,  0.4283,\n",
       "        0.4554,  0.0038,  0.3288, -0.2358, -0.0844,  0.1534,  0.3013,\n",
       "        0.1006, -0.1714,  0.0452,  0.1607, -0.017 , -0.1701],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings_index['hello']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## create embedding matrix, where each row indicates word vector in tokenizer.word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_index = tokenizer.word_index\n",
    "nb_words = min(max_features, len(word_index))\n",
    "embedding_matrix = np.zeros((nb_words, embed_size))\n",
    "for word, i in word_index.items():\n",
    "    if i >= max_features: continue\n",
    "    embedding_vector = embeddings_index.get(word)\n",
    "    if embedding_vector is not None: embedding_matrix[i] = embedding_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30000, 300)"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(159571, 100)"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## define costumised callback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RocAucEvaluation(Callback):\n",
    "    def __init__(self, validation_data=(), interval=1):\n",
    "        super(Callback, self).__init__()\n",
    "\n",
    "        self.interval = interval\n",
    "        self.X_val, self.y_val = validation_data\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        if epoch % self.interval == 0:\n",
    "            y_pred = self.model.predict(self.X_val, verbose=0)\n",
    "            score = roc_auc_score(self.y_val, y_pred)\n",
    "            print(\"\\n ROC-AUC - epoch: %d - score: %.6f \\n\" % (epoch+1, score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## create model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model():\n",
    "    inp = Input(shape=(maxlen, ))\n",
    "    x = Embedding(max_features, embed_size, weights=[embedding_matrix])(inp)\n",
    "    x = SpatialDropout1D(0.2)(x)\n",
    "    x = Bidirectional(GRU(80, return_sequences=True))(x) #bidirectional has two inputs if not specified, see keras doc\n",
    "    avg_pool = GlobalAveragePooling1D()(x) # average over features along time steps direction, here means steps=80\n",
    "    max_pool = GlobalMaxPooling1D()(x)\n",
    "    conc = concatenate([avg_pool, max_pool]) # concatenate along axis of avg or max_pool in the list by default, input must be list of tensors\n",
    "    outp = Dense(6, activation=\"sigmoid\")(conc)\n",
    "    \n",
    "    model = Model(inputs=inp, outputs=outp)\n",
    "    model.compile(loss='binary_crossentropy',\n",
    "                  optimizer='adam',\n",
    "                  metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=get_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 151592 samples, validate on 7979 samples\n",
      "Epoch 1/2\n",
      "\n",
      " ROC-AUC - epoch: 1 - score: 0.986282 \n",
      "\n",
      "151592/151592 - 2013s - loss: 0.0505 - acc: 0.9817 - val_loss: 0.0446 - val_acc: 0.9828\n",
      "Epoch 2/2\n",
      "\n",
      " ROC-AUC - epoch: 2 - score: 0.986960 \n",
      "\n",
      "151592/151592 - 1713s - loss: 0.0378 - acc: 0.9852 - val_loss: 0.0454 - val_acc: 0.9824\n"
     ]
    }
   ],
   "source": [
    "batch_size = 32\n",
    "epochs = 2\n",
    "\n",
    "X_tra, X_val, y_tra, y_val = train_test_split(x_train, y_train, train_size=0.95, random_state=233)\n",
    "RocAuc = RocAucEvaluation(validation_data=(X_val, y_val), interval=1)\n",
    "\n",
    "hist = model.fit(X_tra, y_tra, batch_size=batch_size, epochs=epochs, validation_data=(X_val, y_val),\n",
    "                 callbacks=[RocAuc], verbose=2)\n",
    "\n",
    "\n",
    "y_pred = model.predict(x_test, batch_size=1024)\n",
    "submission[[\"toxic\", \"severe_toxic\", \"obscene\", \"threat\", \"insult\", \"identity_hate\"]] = y_pred\n",
    "submission.to_csv('submission.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
